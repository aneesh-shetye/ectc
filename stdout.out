/scratch/axs10302/ectc/run-45186367
wandb: Currently logged in as: tera_squid. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in /scratch/axs10302/ectc/wandb/run-20240411_154845-mkfibz8r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-river-31
wandb: ‚≠êÔ∏è View project at https://wandb.ai/tera_squid/ectc
wandb: üöÄ View run at https://wandb.ai/tera_squid/ectc/runs/mkfibz8r
wandb: WARNING Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
/ext3/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/ext3/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.
torch.Size([512, 512])
wandb: - 0.021 MB of 0.021 MB uploadedwandb: \ 0.036 MB of 0.036 MB uploaded (0.003 MB deduped)wandb: | 0.036 MB of 0.047 MB uploaded (0.003 MB deduped)wandb: üöÄ View run bright-river-31 at: https://wandb.ai/tera_squid/ectc/runs/mkfibz8r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/tera_squid/ectc
wandb: Synced 7 W&B file(s), 1 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20240411_154845-mkfibz8r/logs
Traceback (most recent call last):
  File "/scratch/axs10302/ectc/pretrain_ectc.py", line 223, in <module>
    main()
  File "/scratch/axs10302/ectc/pretrain_ectc.py", line 116, in main
    torch.multiprocessing.spawn(pretrain, args=(args,), nprocs=args.ngpus_per_node)
  File "/ext3/miniconda3/lib/python3.12/site-packages/torch/multiprocessing/spawn.py", line 241, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ext3/miniconda3/lib/python3.12/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
              ^^^^^^^^^^^^^^
  File "/ext3/miniconda3/lib/python3.12/site-packages/torch/multiprocessing/spawn.py", line 158, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/ext3/miniconda3/lib/python3.12/site-packages/torch/multiprocessing/spawn.py", line 68, in _wrap
    fn(i, *args)
  File "/scratch/axs10302/ectc/pretrain_ectc.py", line 209, in pretrain
    loss = on_diag + args.lambd * off_diag
           ^^^^^^^
NameError: name 'on_diag' is not defined. Did you mean: 'rn_diag'?

